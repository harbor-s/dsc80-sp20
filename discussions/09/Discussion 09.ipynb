{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 9\n",
    "\n",
    "### Due Friday May 29, 11:59:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn: Transformers, Estimators, and Pipelines\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers and Estimators\n",
    "\n",
    "Scikit learn includes two *base* modeling classes: Transfomers and Estimators. Both are classes that are meant to be *fit* on (training) data and then later used to transform (or predict with) unseen data.\n",
    "\n",
    "### Transformers\n",
    "\n",
    "* Transformers take input data and transform it into output data via the `transform` method.\n",
    "* Sometimes transformers need prior information (parameters) about the data before transforming it.\n",
    "    - In this case, the transformer is *fit* using the `fit` method on training data to estimate the parameters.\n",
    "    - Once fit, the transformer may then be applied to `test` data (or unseen, new data).\n",
    "* Fit parameters are accessed via an instance variable that ends in an *underscore*.\n",
    "\n",
    "**Question 1** Using `Binarizer`, transform the `city-mpg` and `highway-mpg` column to 0 if the mpg is less than or equal to 25 and 1 if it's greater than 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('cars.csv')\n",
    "Binarizer(threshold=25).transform(cars[['city-mpg','highway-mpg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2** Using `FunctionTransformer`, transform the `city-mpg` and `highway-mpg` columns to a log-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.04452244],\n",
       "       [3.04452244],\n",
       "       [2.94443898],\n",
       "       [3.17805383],\n",
       "       [2.89037176],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [2.83321334],\n",
       "       [3.13549422],\n",
       "       [3.13549422],\n",
       "       [3.04452244],\n",
       "       [3.04452244],\n",
       "       [2.99573227],\n",
       "       [2.77258872],\n",
       "       [2.77258872],\n",
       "       [2.7080502 ],\n",
       "       [3.8501476 ],\n",
       "       [3.63758616],\n",
       "       [3.63758616],\n",
       "       [3.61091791],\n",
       "       [3.4339872 ],\n",
       "       [3.17805383],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.17805383],\n",
       "       [2.94443898],\n",
       "       [3.8918203 ],\n",
       "       [3.4339872 ],\n",
       "       [3.63758616],\n",
       "       [3.40119738],\n",
       "       [3.40119738],\n",
       "       [3.40119738],\n",
       "       [3.40119738],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [3.17805383],\n",
       "       [3.21887582],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [2.7080502 ],\n",
       "       [2.7080502 ],\n",
       "       [2.56494936],\n",
       "       [3.40119738],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.25809654],\n",
       "       [3.25809654],\n",
       "       [3.25809654],\n",
       "       [3.25809654],\n",
       "       [3.25809654],\n",
       "       [2.94443898],\n",
       "       [3.4339872 ],\n",
       "       [3.09104245],\n",
       "       [3.09104245],\n",
       "       [3.09104245],\n",
       "       [3.09104245],\n",
       "       [2.77258872],\n",
       "       [2.77258872],\n",
       "       [2.63905733],\n",
       "       [2.63905733],\n",
       "       [2.94443898],\n",
       "       [3.61091791],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.17805383],\n",
       "       [3.13549422],\n",
       "       [3.21887582],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [3.21887582],\n",
       "       [3.21887582],\n",
       "       [3.13549422],\n",
       "       [3.13549422],\n",
       "       [3.4339872 ],\n",
       "       [3.80666249],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [2.83321334],\n",
       "       [2.83321334],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [2.83321334],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [3.33220451],\n",
       "       [2.94443898],\n",
       "       [3.21887582],\n",
       "       [2.94443898],\n",
       "       [3.33220451],\n",
       "       [2.94443898],\n",
       "       [3.21887582],\n",
       "       [2.94443898],\n",
       "       [3.33220451],\n",
       "       [2.89037176],\n",
       "       [3.61091791],\n",
       "       [3.17805383],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.17805383],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [2.83321334],\n",
       "       [2.83321334],\n",
       "       [2.83321334],\n",
       "       [3.04452244],\n",
       "       [3.04452244],\n",
       "       [3.04452244],\n",
       "       [3.04452244],\n",
       "       [2.94443898],\n",
       "       [2.94443898],\n",
       "       [3.4339872 ],\n",
       "       [3.25809654],\n",
       "       [3.25809654],\n",
       "       [3.4657359 ],\n",
       "       [3.33220451],\n",
       "       [3.25809654],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [3.33220451],\n",
       "       [3.21887582],\n",
       "       [3.13549422],\n",
       "       [3.13549422],\n",
       "       [3.55534806],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.4339872 ],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [3.40119738],\n",
       "       [3.40119738],\n",
       "       [3.52636052],\n",
       "       [3.63758616],\n",
       "       [3.63758616],\n",
       "       [3.33220451],\n",
       "       [3.33220451],\n",
       "       [3.36729583],\n",
       "       [3.36729583],\n",
       "       [3.25809654],\n",
       "       [3.25809654],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [3.36729583],\n",
       "       [3.40119738],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [2.99573227],\n",
       "       [2.94443898],\n",
       "       [2.99573227],\n",
       "       [2.94443898],\n",
       "       [3.61091791],\n",
       "       [3.29583687],\n",
       "       [3.61091791],\n",
       "       [3.29583687],\n",
       "       [3.29583687],\n",
       "       [3.61091791],\n",
       "       [3.25809654],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [2.94443898],\n",
       "       [3.49650756],\n",
       "       [3.21887582],\n",
       "       [3.13549422],\n",
       "       [3.13549422],\n",
       "       [3.17805383],\n",
       "       [3.17805383],\n",
       "       [2.83321334],\n",
       "       [2.83321334],\n",
       "       [3.13549422],\n",
       "       [2.94443898],\n",
       "       [2.89037176],\n",
       "       [3.25809654],\n",
       "       [2.94443898]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FunctionTransformer(func=np.log).transform(cars[['city-mpg']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most transformers you will use will require being *fit to training data* before using it. An example of this is one-hot-encoding: before applying one-hot encoding to a column, you must determine the number of distinct values in the column (as that number determines the number of columns in the output).\n",
    "\n",
    "**Question 3** *(Fit transformers properly handle unseen values)*\n",
    "\n",
    "1. One-hot encode the `body-style` column using `OneHotEncoder`. What is the dimension of the output? Which column corresponds to which value of `body-style`? (If you can't remember the attribute name, look up the documentation!)\n",
    "1. Fit a `OneHotEncoder` on the *first 5 rows* of the `body-style` column. Use this 'training data' to one-hot-encode the `body-style` in rest of the dataset. Why does it throw an exception? Look at the documentation -- what is the relevant parameter to avoid this? What are the implications of setting this parameter? What is the dimension of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body-style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>convertible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hardtop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hatchback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wagon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [convertible, hardtop, hatchback, sedan, wagon]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotEncoder().fit(cars[['body-style']]).transform(cars[['body-style']]).toarray()\n",
    "cars[['body-style']].groupby('body-style').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you observed, the categories of `OneHotEncoder` are learned from training data and saved as an attribute of the transformer. These categories are then used to transform new, unseen data which is then used by other pieces of the ML pipeline.\n",
    "\n",
    "Below is an illustration of why *fitting* a transformer is so important:\n",
    "\n",
    "*The dangers of `pd.get_dummies`*: Pandas offers it's own one-hot encoder called `get_dummies`. This function is stateless; every time it's called, it determines the categories of the input data and one-hot encodes that data using those categories. However, as you saw in the above question, this is not a realistic use of the function!\n",
    "\n",
    "To illustrate this:\n",
    "1. We will create a one-hot encoding using scikit-learn that we will pass into a linear regression model.\n",
    "1. We will create a *stateless* one-hot encoder that we will pass into a linear regression model.\n",
    "\n",
    "Both of these models will be trained on the first 5 rows of the dataset; the rest will be used as 'unseen' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cars[['body-style']].head(5), cars['price'].head(5)\n",
    "X_test, y_test = cars[['body-style']].tail(-5), cars['price'].tail(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using sklearn transformers. What are the categories of the OneHotEncoder?\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "lr = LinearRegression()\n",
    "\n",
    "ohe.fit(X_train)\n",
    "features = ohe.transform(X_train)\n",
    "lr.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15700. , 15700. , 15732.5, 15700. , 15700. , 15700. , 15700. ,\n",
       "       15700. , 15700. , 15700. ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on the new data using the fit model:\n",
    "lr.predict(ohe.transform(X_test))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using a stateless one-hot encoder.\n",
    "ohe = FunctionTransformer(pd.get_dummies, validate=False)\n",
    "lr = LinearRegression()\n",
    "\n",
    "ohe.fit(X_train)\n",
    "features = ohe.transform(X_train)\n",
    "lr.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (188,5) and (3,) not aligned: 5 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-eb8eed0635bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# debug this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 206\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (188,5) and (3,) not aligned: 5 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# debug this!\n",
    "lr.predict(ohe.transform(X_test))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Even worse, there are cases where such an ML pipeline doesn't even throw an exception -- the incorrect columns get silently passed on. \n",
    "\n",
    "**The below predictions are wrong! Can you tell that it's wrong?** Debugging statistical output is notoriously hard -- this is why statistical analysis of the output data is always an important step to check your work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cars[['body-style']].head(5), cars['price'].head(5)\n",
    "X_test, y_test = cars[['body-style']].iloc[5:20], cars['price'].iloc[5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = FunctionTransformer(pd.get_dummies, validate=False)\n",
    "lr = LinearRegression()\n",
    "\n",
    "ohe.fit(X_train)\n",
    "features = ohe.transform(X_train)\n",
    "lr.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WRONG! debug this! \n",
    "lr.predict(ohe.transform(X_test))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building custom Transformers\n",
    "\n",
    "Building your own transformer class is easy! There is are convenient base-classes you can inherit: `TranformerMixin` and `BaseEstimator`. To subclass these classes, you need to:\n",
    "1. implement the `fit` method, and\n",
    "2. implement the `transform` method.\n",
    "Once you have done that, you can use your custom transformer as part of a `Pipeline` that can leverage all the nice features of scikit-learn (like feature-selection libraries and cross-validation).\n",
    "\n",
    "To get acquainted with the structure of a transformer, it's useful to look at `sklearn` source code. First, you will walk through the source code of the `Binarizer` transformer ([source code](https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/preprocessing/data.py#L1789)).\n",
    "\n",
    "The source code is included below. Note, that there is a lot of boiler-plate code, but the *transform* method is the relevant method. (Why does the fit method do nothing?)\n",
    "\n",
    "```\n",
    "class Binarizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Binarize data (set feature values to 0 or 1) according to a threshold\n",
    "    Values greater than the threshold map to 1, while values less than\n",
    "    or equal to the threshold map to 0. With the default threshold of 0,\n",
    "    only positive values map to 1.\n",
    "    Binarization is a common operation on text count data where the\n",
    "    analyst can decide to only consider the presence or absence of a\n",
    "    feature rather than a quantified number of occurrences for instance.\n",
    "    It can also be used as a pre-processing step for estimators that\n",
    "    consider boolean random variables (e.g. modelled using the Bernoulli\n",
    "    distribution in a Bayesian setting).\n",
    "    Read more in the :ref:`User Guide <preprocessing_binarization>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : float, optional (0.0 by default)\n",
    "        Feature values below or equal to this are replaced by 0, above it by 1.\n",
    "        Threshold may not be less than 0 for operations on sparse matrices.\n",
    "    copy : boolean, optional, default True\n",
    "        set to False to perform inplace binarization and avoid a copy (if\n",
    "        the input is already a numpy array or a scipy.sparse CSR matrix).\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.preprocessing import Binarizer\n",
    "    >>> X = [[ 1., -1.,  2.],\n",
    "    ...      [ 2.,  0.,  0.],\n",
    "    ...      [ 0.,  1., -1.]]\n",
    "    >>> transformer = Binarizer().fit(X)  # fit does nothing.\n",
    "    >>> transformer\n",
    "    Binarizer(copy=True, threshold=0.0)\n",
    "    >>> transformer.transform(X)\n",
    "    array([[1., 0., 1.],\n",
    "           [1., 0., 0.],\n",
    "           [0., 1., 0.]])\n",
    "    Notes\n",
    "    -----\n",
    "    If the input is a sparse matrix, only the non-zero values are subject\n",
    "    to update by the Binarizer class.\n",
    "    This estimator is stateless (besides constructor parameters), the\n",
    "    fit method does nothing but is useful when used in a pipeline.\n",
    "    See also\n",
    "    --------\n",
    "    binarize: Equivalent function without the estimator API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold=0.0, copy=True):\n",
    "        self.threshold = threshold\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Do nothing and return the estimator unchanged\n",
    "        This method is just there to implement the usual API and hence\n",
    "        work in pipelines.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "        \"\"\"\n",
    "        check_array(X, accept_sparse='csr')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"Binarize each element of X\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
    "            The data to binarize, element by element.\n",
    "            scipy.sparse matrices should be in CSR format to avoid an\n",
    "            un-necessary copy.\n",
    "        copy : bool\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        return binarize(X, threshold=self.threshold, copy=copy)\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'stateless': True}\n",
    "```\n",
    "\n",
    "The relevant (portion of the) function `binarize` from the transform method is here:\n",
    "\n",
    "```\n",
    "def binarize(X, threshold=0.0, copy=True):\n",
    "    ...\n",
    "    cond = X > threshold\n",
    "    not_cond = np.logical_not(cond)\n",
    "    X[cond] = 1\n",
    "    X[not_cond] = 0\n",
    "    return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4** \n",
    "\n",
    "As a warm-up, create a transformer that drops the `i`th row of an input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Does nothing! Stateless!\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Drops the ith column of X, where i=index\n",
    "        \"\"\"\n",
    "        \n",
    "        return X.drop(X.columns[self.index], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>body-style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>convertible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>convertible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>hatchback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>volvo</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>volvo</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>volvo</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>volvo</td>\n",
       "      <td>diesel</td>\n",
       "      <td>turbo</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>volvo</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            make fuel-type aspiration   body-style\n",
       "0    alfa-romero       gas        std  convertible\n",
       "1    alfa-romero       gas        std  convertible\n",
       "2    alfa-romero       gas        std    hatchback\n",
       "3           audi       gas        std        sedan\n",
       "4           audi       gas        std        sedan\n",
       "..           ...       ...        ...          ...\n",
       "188        volvo       gas        std        sedan\n",
       "189        volvo       gas      turbo        sedan\n",
       "190        volvo       gas        std        sedan\n",
       "191        volvo    diesel      turbo        sedan\n",
       "192        volvo       gas      turbo        sedan\n",
       "\n",
       "[193 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd = ColumnDropper(index=3)\n",
    "cd.transform(cars.iloc[:,:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Columns that don't have much variation are not very useful for prediction. An extreme case is when a column has only a single value.  Create a \"feature selection\" transformer that drops any columns that don't have a standard-deviation greater than an input threshold.\n",
    "\n",
    "* What needs to be calculated during the fitting process? When is the standard deviation calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LowStdColumnDropper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, thresh=0):\n",
    "        '''\n",
    "        Drops columns whose standard deviation is less than thresh.\n",
    "        '''\n",
    "        self.thresh = thresh\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.columns_ = X.columns[X.std() > self.thresh]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "        \n",
    "        return X[self.columns_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.7</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>2952</td>\n",
       "      <td>141</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>16845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.7</td>\n",
       "      <td>68.8</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3049</td>\n",
       "      <td>141</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>19045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.7</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3012</td>\n",
       "      <td>173</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.7</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3217</td>\n",
       "      <td>145</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>22470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.7</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3062</td>\n",
       "      <td>141</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>22625.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wheel-base  length  width  height  curb-weight  engine-size  \\\n",
       "0          88.6   168.8   64.1    48.8         2548          130   \n",
       "1          88.6   168.8   64.1    48.8         2548          130   \n",
       "2          94.5   171.2   65.5    52.4         2823          152   \n",
       "3          99.8   176.6   66.2    54.3         2337          109   \n",
       "4          99.4   176.6   66.4    54.3         2824          136   \n",
       "..          ...     ...    ...     ...          ...          ...   \n",
       "188       109.1   188.7   68.9    55.5         2952          141   \n",
       "189       109.1   188.7   68.8    55.5         3049          141   \n",
       "190       109.1   188.7   68.9    55.5         3012          173   \n",
       "191       109.1   188.7   68.9    55.5         3217          145   \n",
       "192       109.1   188.7   68.9    55.5         3062          141   \n",
       "\n",
       "     compression-ratio  horsepower  peak-rpm  city-mpg  highway-mpg    price  \n",
       "0                  9.0         111      5000        21           27  13495.0  \n",
       "1                  9.0         111      5000        21           27  16500.0  \n",
       "2                  9.0         154      5000        19           26  16500.0  \n",
       "3                 10.0         102      5500        24           30  13950.0  \n",
       "4                  8.0         115      5500        18           22  17450.0  \n",
       "..                 ...         ...       ...       ...          ...      ...  \n",
       "188                9.5         114      5400        23           28  16845.0  \n",
       "189                8.7         160      5300        19           25  19045.0  \n",
       "190                8.8         134      5500        18           23  21485.0  \n",
       "191               23.0         106      4800        26           27  22470.0  \n",
       "192                9.5         114      5400        19           25  22625.0  \n",
       "\n",
       "[193 rows x 12 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvd = LowStdColumnDropper(thresh=1)\n",
    "lvd.fit(cars.select_dtypes('number'))\n",
    "lvd.transform(cars.select_dtypes('number'))\n",
    "#cars.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wheel-base', 'width', 'height', 'bore', 'stroke', 'compression-ratio',\n",
       "       'city-mpg', 'highway-mpg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.select_dtypes('number').columns[cars.select_dtypes('number').std() < 12]\n",
    "#cars.select_dtypes('number').std()[cars.select_dtypes('number').std() < 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Pipelines\n",
    "\n",
    "Pipelines are ways of chaining transformers and estimators together. \n",
    "* A **Pipeline** object is a sequence of transformers that perhaps end with estimator.\n",
    "* When you call `.fit(X, y)` on a pipeline, the pipeline calls `fit_transform` on each successive transformer in the pipeline, passing the transformed data to the next transformer in the sequence.\n",
    "* A pipeline that consists of a sequence of transformers is itself a transformer.\n",
    "* A pipeline that consists of a sequence of transformers, followed by an estimator, is itself an estimator.\n",
    "    - These observations allow you put pipelines inside of other pipelines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6** Create a *single* pipeline that consists of a `OneHotEncoder`, followed by a `LowStdColumnDropper`, followed by a `LinearRegression` model. That is, one-hot encode the categorical features, drop the low-variance columns, and use those features to fit a linear regression model. Your threshold for \"small standard deviation\" should be `0.1`. \n",
    "\n",
    "*Remark:* Be sure to pass `sparse=False` into `OneHotEncoder` (or else, make your `LowStdColumnDropper` handle sparse matrices).\n",
    "\n",
    "How many columns did your pipeline drop? (Use the `named_steps` attribute!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting columns together using `ColumnTransformer`\n",
    "\n",
    "You can run many different transformers in parallel on different subsets of columns using `ColumnTransformer` (see the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer)).\n",
    "\n",
    "One common pattern for using `ColumnTransformer` is to create a transformer pipeline for each kind of data in your dataset and use `ColumnTransformer` to put the transformed features together into a single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "\n",
    "Create a general pipeline that transforms different data-kinds with appropriate generic features (e.g. one-hot-encoder, ordinal-encoder) by filling in the `...` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_cols = ...\n",
    "ordinal_cols = ...\n",
    "nominal_cols = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_pipeline = Pipeline([...])\n",
    "ordinal_pipeline = Pipeline([...])\n",
    "nominal_pipeline = Pipeline([...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_eng_pipeline = ColumnTransformer([\n",
    "    ('quant', quantitative_pipeline, quantitative_cols),\n",
    "    ('ordin', ordinal_pipeline, ordinal_cols),\n",
    "    ('nomin', nominal_pipeline, nominal_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([feature_eng_pipeline, LinearRegression()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8** \n",
    "\n",
    "Fit the pipeline and predict with it. Check the outputs at each step using `named_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished? Turn in Question 5 for Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
