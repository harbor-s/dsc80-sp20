{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 04\n",
    "\n",
    "### Due Date: Tuesday April 28th, Midnight (11:59 PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom Lab Hours\n",
    "- Follow instructions on this link: https://docs.google.com/document/d/16qZpPSYhxwQDMcn-lGQjC-J-PzppLevv_mANLt2ko8g/edit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab04 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login time questions\n",
    "\n",
    "Imagine that you own an online store and you'd like to monitor the visits to your site. You've collected some data that you store in login_table.csv. It contains the information about different login dates and times for different users. Some users are unique, some visited your store multiple times.\n",
    "\n",
    "You need to answer a few questions below in order to understand the login patters of your users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'login_table.csv')\n",
    "login = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Write a function `latest_login` which takes in a dataframe like `login` and outputs a dataframe, indexed by `Login Id`, of the login that occurs at the latest time-of-day for each user. Latest time-of-day is as it says: the latest time, **regardless of how recent the day is**.\n",
    "\n",
    "For example, if a user always logs in once per day at Noon, but her most recent log in happened to be at 8:00PM, then her latest log-in time becomes 8:00PM.\n",
    "\n",
    "Note: you do not need to import datetime. Look into how pandas has its own built in methods for dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Login Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>2017-12-28 20:21:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>2017-12-14 12:33:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>2017-12-18 18:04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>2018-01-04 10:43:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>2017-03-15 14:47:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>2018-01-02 12:05:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>2017-12-30 14:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>2018-01-01 17:45:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>2018-01-03 11:52:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>2018-01-04 13:13:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Time\n",
       "Login Id                     \n",
       "381       2017-12-28 20:21:33\n",
       "393       2017-12-14 12:33:57\n",
       "412       2017-12-18 18:04:18\n",
       "413       2018-01-04 10:43:43\n",
       "419       2017-03-15 14:47:43\n",
       "...                       ...\n",
       "1302      2018-01-02 12:05:59\n",
       "1304      2017-12-30 14:06:23\n",
       "1305      2018-01-01 17:45:11\n",
       "1306      2018-01-03 11:52:14\n",
       "1307      2018-01-04 13:13:45\n",
       "\n",
       "[433 rows x 1 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "login.groupby('Login Id').max()\n",
    "pd.to_datetime(login['Time']).apply(lambda x: x.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "As a site owner, you would like to see how often users return to your site. You've noticed that there are users who have several logins and users who logged in only once. Of those users that logged in more than once, you are interested in finding the shortest amount of time elapsed between two consecutive logins for each of these users.\n",
    "\n",
    "Write a function `smallest_ellapsed` which takes in a dataframe like `login` and outputs a dataframe, indexed by Login ID, containing the shortest time elapsed for each user. Any users who haven't logged in more than once should not be included in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "login_dt = login.copy()\n",
    "login_dt['Time'] = pd.to_datetime(login_dt['Time'])\n",
    "login_dt.sort_values('Login Id', ascending=False)\n",
    "\n",
    "result = login_dt.groupby('Login Id')\\\n",
    "        .apply(lambda x: x.diff().min())\\\n",
    "        .dropna().drop('Login Id', axis=1)\n",
    "\n",
    "len(result)\n",
    "result.loc[1233, \"Time\"].days\n",
    "#for name, group in groups:\n",
    "#    print(login.loc[login['Login Id']==name].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot tables\n",
    "\n",
    "**Question 3**\n",
    "\n",
    "The pivot table allows you to group the entries of a dataframe into a two-dimensional table that provides a (multidimensional) summarization of the data. You are given a simple dataset, `sales.csv`, and are asked to solve a few simple problems using a `pivot table`.  \n",
    "\n",
    "We have provided the outline for your pivot tables. Your values will be different.\n",
    "\n",
    "* Write a function `total_seller` that takes `sales` dataframe and returns a pivot table that contains a total for each seller, indexed by a name.\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"15%\"/>\n",
    "\n",
    "* Write a function `product_name` that takes `sales` dataframe and returns a pivot table that contains a total for each seller, indexed by a product.\n",
    "\n",
    "<img src=\"imgs/image_1.png\" width=\"25%\"/>\n",
    "\n",
    "* Write a function `count_product` that takes `sales` dataframe and returns a pivot table that contains the total amount of items sold product wise, name wise per date. Replaces `NaNs` with 0s. \n",
    "\n",
    "<img src=\"imgs/image_2.png\" width=\"35%\"/>\n",
    "\n",
    "* Write a function `total_by_month` that takes `sales` dataframe and returns a pivot table that contains the total amount name wise, product wise per `month`. Replaces `NaNs` with 0s.\n",
    "\n",
    "<img src=\"imgs/image_3.png\" width=\"40%\"/>\n",
    "\n",
    "\n",
    "Note: Here is a <a href = \"https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html\"> link </a> to a great source that provides an overview of the pivot tables with mane examples from the Titanic dataset. \n",
    "\n",
    "If your \"Total\" title is on the right side of the DataFrame instead of the left as seen above, as long as you are passing the doctests you should be fine. This is likely due to an issue with pandas versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Smith</td>\n",
       "      <td>book</td>\n",
       "      <td>01.01.2012</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Jones</td>\n",
       "      <td>pen</td>\n",
       "      <td>02.20.2013</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Trump</td>\n",
       "      <td>hotel</td>\n",
       "      <td>03.03.2015</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Smith</td>\n",
       "      <td>book</td>\n",
       "      <td>05.10.2013</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jones</td>\n",
       "      <td>book</td>\n",
       "      <td>02.20.2013</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Trump</td>\n",
       "      <td>boat</td>\n",
       "      <td>03.30.2017</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Smith</td>\n",
       "      <td>ruler</td>\n",
       "      <td>07.05.2014</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Jones</td>\n",
       "      <td>ruler</td>\n",
       "      <td>02.25.2015</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Trump</td>\n",
       "      <td>book</td>\n",
       "      <td>03.03.2015</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Smith</td>\n",
       "      <td>pen</td>\n",
       "      <td>01.01.2012</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Jones</td>\n",
       "      <td>ruler</td>\n",
       "      <td>02.20.2013</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Trump</td>\n",
       "      <td>pen</td>\n",
       "      <td>03.03.2015</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Product        Date  Total\n",
       "0   Smith    book  01.01.2012    200\n",
       "1   Jones     pen  02.20.2013    300\n",
       "2   Trump   hotel  03.03.2015    100\n",
       "3   Smith    book  05.10.2013   2000\n",
       "4   Jones    book  02.20.2013     30\n",
       "5   Trump    boat  03.30.2017    700\n",
       "6   Smith   ruler  07.05.2014   2100\n",
       "7   Jones   ruler  02.25.2015    350\n",
       "8   Trump    book  03.03.2015   1000\n",
       "9   Smith     pen  01.01.2012   2500\n",
       "10  Jones   ruler  02.20.2013   3000\n",
       "11  Trump     pen  03.03.2015    150"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_fp = os.path.join('data', 'sales.csv')\n",
    "sales = pd.read_csv(sales_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">Jones</td>\n",
       "      <td>book</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pen</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ruler</td>\n",
       "      <td>3350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">Smith</td>\n",
       "      <td>book</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pen</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ruler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"4\" valign=\"top\">Trump</td>\n",
       "      <td>boat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>book</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total                          \n",
       "Month         February January  July March   May\n",
       "Name  Product                                   \n",
       "Jones book          30       0     0     0     0\n",
       "      pen          300       0     0     0     0\n",
       "      ruler       3350       0     0     0     0\n",
       "Smith book           0     200     0     0  2000\n",
       "      pen            0    2500     0     0     0\n",
       "      ruler          0       0  2100     0     0\n",
       "Trump boat           0       0     0   700     0\n",
       "      book           0       0     0  1000     0\n",
       "      hotel          0       0     0   100     0\n",
       "      pen            0       0     0   150     0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.total_by_month(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A distribution of Skittles\n",
    "\n",
    "[Skittles](https://en.wikipedia.org/wiki/Skittles_(confectionery)) are made in two locations in the United States: Yorkville, Illinois and Waco, Texas. In these factories, Skittles of different colors are made separately by different machines and combined/packaged into bags for sale. The tab-separated file `skittles.tsv` contains the contents of 468 bags of Skittles.\n",
    "\n",
    "Most people have preferences for their favorite flavor and there is a surprising amount of variation among the distribution of flavors in each bag.\n",
    "\n",
    "Look at the variation by bag in the dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red</th>\n",
       "      <th>orange</th>\n",
       "      <th>yellow</th>\n",
       "      <th>green</th>\n",
       "      <th>purple</th>\n",
       "      <th>Factory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>Yorkville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>Yorkville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>Yorkville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     red  orange  yellow  green  purple    Factory\n",
       "0     10      15      11      7      18  Yorkville\n",
       "1      5      12      17     15      10  Yorkville\n",
       "2     16      11      15     11       9       Waco\n",
       "3     15       8      13     16       7       Waco\n",
       "4     11      14      20      8       7       Waco\n",
       "..   ...     ...     ...    ...     ...        ...\n",
       "463   11      11      12     13      11       Waco\n",
       "464   17      10       8     11      12       Waco\n",
       "465    9      14      12     10      15       Waco\n",
       "466   12      14      11     10      10       Waco\n",
       "467   11       8      12     13      15  Yorkville\n",
       "\n",
       "[468 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skittles_fp = os.path.join('data', 'skittles.tsv')\n",
    "skittles = pd.read_csv(skittles_fp, sep='\\t')\n",
    "skittles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between Yorkville and Waco\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "First, you will investigate if the machine that mixes together the Skittles of different colors might favor one color over another. Use a permutation test to assess whether, on average, bags made in Yorkville have the same number of orange skittles as bags made in Waco. Do this by following the outline below:\n",
    "1. Create a function `diff_of_means` that takes in a dataframe of counts of skittles (like `skittles`) and their origin and returns the *absolute* difference of means between the number of orange Skittles per bag from Yorkville and Waco.\n",
    "2. Create a function `simulate_null` that takes in a dataframe of counts of skittles (like `skittles`) and their origin, and returns one instance of the test-statistic under the null hypothesis.\n",
    "3. Create a function `pval_orange` that takes in a dataframe of counts of skittles (like `skittles`) and their origin, and calculates the p-value for the permutation test using `1000` trials.\n",
    "\n",
    "Plot the observed statistic, along with the histogram for the simulated distribution, to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factory\n",
       "Waco         12.068182\n",
       "Yorkville    11.467742\n",
       "Name: orange, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orange_means = skittles.groupby('Factory')['orange'].mean()\n",
    "abs(orange_means[0] - orange_means[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.pval_orange(skittles,'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = skittles.groupby('Factory').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Use your work from above to decide which colors tend to differ the most between the two locations on average. Create a function `ordered_colors` that returns your answer as an ordered list from \"most different\" to \"least different\" between the two locations. Your list should be a *hard-coded* list, where each element has the form `(color, p-value)`.\n",
    "\n",
    "Even though there is randomness in the color composition in each bag, this list gives the likelihood that the machines have a systematic, meaningful, difference in how they blend the colors in each bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n",
      "0.083\n",
      "orange\n",
      "0.008\n",
      "yellow\n",
      "0.0\n",
      "green\n",
      "0.303\n",
      "purple\n",
      "0.966\n"
     ]
    }
   ],
   "source": [
    "for color in colors.columns:\n",
    "    print(color)\n",
    "    print(lab.pval_orange(skittles,color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, False, True]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = [('yellow', 0.0), ('orange', 0.008), ('red', 0.083), ('green', 303), ('purple', 0.966)]\n",
    "([isinstance(x[1], float) for x in out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Now, suppose you would like to assess whether the two locations make similar amounts of each color overall. That is:\n",
    "* Combine and count up all the Skittles of each color that were made in Yorkville \n",
    "* Combine and count up all the Skittles of each color that were made in Waco\n",
    "\n",
    "Are these distributions of colors similar? Is the variation among the bags due to each factory making different amounts of each color?\n",
    "\n",
    "Use a permutation test to assess whether the distribution of colors of Yorkville Skittles is statistically significantly different than those made in Waco. Set a significance level of 0.01 and determine whether you can reject a null hypothesis that answer the question above using a permutation test with 1000 trials. For your test statistic, use the total-variation-distance (TVD).\n",
    "\n",
    "Create a function `same_color_distribution` of zero variables that outputs a hard-coded tuple with the p-value and whether you 'Fail to Reject' or 'Reject' the null hypothesis.\n",
    "\n",
    "For this question, the following references may be useful:\n",
    "* For TVD reference, see [DSC 10](https://www.inferentialthinking.com/chapters/11/2/Multiple_Categories.html) and [Lecture 04](https://github.com/ucsd-ets/dsc80-sp20/tree/master/lectures/04%20-%20Hypothesis%20Testing)\n",
    "* For permutation test reference, see [DSC 10](https://www.inferentialthinking.com/chapters/12/Comparing_Two_Samples.html) and [Lecture 07](https://github.com/ucsd-ets/dsc80-sp20/tree/master/lectures/07%20-%20Permutation%20Tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvd(sk):\n",
    "    return sum(abs(sk.groupby('Factory').sum().apply(lambda x: x/x.sum(), axis=1).iloc[0] - sk.groupby('Factory').sum().apply(lambda x: x/x.sum(), axis=1).iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red</th>\n",
       "      <th>orange</th>\n",
       "      <th>yellow</th>\n",
       "      <th>green</th>\n",
       "      <th>purple</th>\n",
       "      <th>Factory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>Yorkville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>Yorkville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Waco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>Yorkville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     red  orange  yellow  green  purple    Factory\n",
       "0     10      15      11      7      18  Yorkville\n",
       "1      5      12      17     15      10  Yorkville\n",
       "2     16      11      15     11       9       Waco\n",
       "3     15       8      13     16       7       Waco\n",
       "4     11      14      20      8       7       Waco\n",
       "..   ...     ...     ...    ...     ...        ...\n",
       "463   11      11      12     13      11       Waco\n",
       "464   17      10       8     11      12       Waco\n",
       "465    9      14      12     10      15       Waco\n",
       "466   12      14      11     10      10       Waco\n",
       "467   11       8      12     13      15  Yorkville\n",
       "\n",
       "[468 rows x 6 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skittles_shuffled = skittles.copy()\n",
    "skittles_shuffled['Factory'] = skittles['Factory'].sample(replace=False, frac=1)\n",
    "tvd(skittles)\n",
    "skittles_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.array(results)\n",
    "np.count_nonzero(results >= tvd(skittles)) / len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(1000):\n",
    "    skittles_shuffled = skittles.copy()\n",
    "    skittles_shuffled['Factory'] = skittles['Factory'].sample(replace=False, frac=1).reset_index(drop=True)\n",
    "    results.append(tvd(skittles_shuffled))\n",
    "results = np.array(results)\n",
    "np.count_nonzero(results >= tvd(skittles)) / len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis vs Permutation Testing\n",
    "\n",
    "**Question 7**\n",
    "\n",
    "In each of the following scenarios, decide  whether  a  permutation test is appropriate to determine if there is a  significant difference between the quantities described. If a permutation test is appropriate, mark 'P'. Otherwise, mark 'H'.\n",
    "\n",
    "Record your answers in the function `perm_vs_hyp` that outputs a list of length 5, containing the values 'H' and 'P\"\n",
    "\n",
    "1. Compare the DSC 80 pass rate between second years and third years who take the class.\n",
    "    - Permutation or Hypothesis test?\n",
    "2. Compare the proportion of Data Science majors who have completed DSC 80 and the proportion of Data Science minors who have completed DSC 80.\n",
    "    - Permutation or Hypothesis test?\n",
    "3. Compare the proportion of students who have iPhones to the proportion of students who have Android phones.\n",
    "    - Permutation or Hypothesis test?\n",
    "4. Out of the DSC 80 students, the professor asks students whether they prefer DSC 10 or DSC 20.  Compare the proportion of students who prefer DSC 10 to the proportion who prefer DSC 20.\n",
    "    - Permutation or Hypothesis test?\n",
    "5. Compare the attendance rate of classes that use iClickers vs classes that do not use iClickers.\n",
    "    - Permutation or Hypothesis test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Missingness\n",
    "\n",
    "### Missing by Design (MD)\n",
    "- The missing field is deliberately missing. The missing field is deliberately not collected or set to null (hence, \"missing by design\")\n",
    "- The missingness can be exactly predicted when a column will be null, with only knowledge of the other columns using a function of the rows of the dataset\n",
    "\n",
    "### Missing Completely at Random (MCAR)\n",
    "- The missingness of missing value isn't related to the actual, unreported value itself, nor the values in any other fields. The missingness is not systematic.\n",
    "- The missingness is unconditionally uniform across rows. MCAR doesn't bias the observed data.\n",
    "- There is no relationship between the missing data and the any of the other data, observed or missing.\n",
    "\n",
    "### Missing at Random (MAR)\n",
    "- The missingness of the missing value has nothing to do with the value itself, but may be related to another field.\n",
    "- The missingness is uniform across rows, perhaps conditional on another column. MAR biases the observed data, but is fixable.\n",
    "- There is a systematic relationship between the missing values and the observed data (but not the missing values themselves).\n",
    "- Difference between MD and MAR: If you can *exactly/always* determine missingness on other columns, the missingness is MD. If there is just some sort of systematic relationship between the missing columns/values and other columns/values that may help us predict missingness, the missingness is MAR.\n",
    "\n",
    "### Non-Ignorable (NI)\n",
    "- The missingness of the missing value is related to the actual, unreported value.\n",
    "- NI biases the observed data in unobservable ways.\n",
    "- There is relationship between the propensity of a value to be missing and its value.\n",
    "\n",
    "*Note:* In class, we sometimes refer to non-ignorable missingness as \"not missing at random (NMAR)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missingness Mechanisms\n",
    "\n",
    "For each of the following scenarios, choose the most likely mechanism for the missing data in the dataset described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After-purchase surveys\n",
    "\n",
    "**Question 8**\n",
    "\n",
    "You run a small e-commerce website and send surveys out to customers after they purchase an item from your store. The survey asks whether the customer is satisfied with their purchase (\"Yes\" or \"No\"). Below, you are presented with possible datasets, each of which contains a column `satisfied` as described above, as well as a `customer_id` number corresponding to the order. The column `satisfied` is missing data. \n",
    "\n",
    "For each of the following datasets, label the column `satisfied` as being `MD`, `MCAR`, `MAR`, `NI`.\n",
    "\n",
    "1. The dataset consists only of the columns `customer_id` and `satisfied`.\n",
    "2. The dataset contains the `customer_id` of every customer with an account, even if they didn't make a purchase. Also, in this case, you notice everyone who was sent a survey filled it out.\n",
    "3. The dataset contains a column specifying if the user later returned the item.\n",
    "4. The dataset contains a column with the serial number for the item purchased.\n",
    "5. The dataset contains a column with the price of the item purchased.\n",
    "\n",
    "Record your answers in the function `after_purchase` that outputs a list of length 5, containing the values `MD`, `MCAR`, `MAR`, `NI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['MAR', 'MD', '', '', '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous missingness questions\n",
    "\n",
    "**Question 9**\n",
    "\n",
    "In each of the following scenarios, choose the best answer. Return your answers in a function `multiple_choice`.\n",
    "\n",
    "1. UCSD has recently adopted GrubHub as the food pre-ordering app for campus restaurants, so you can order your food ahead of time and stop by before your next class. In a table of GrubHub app orders, which contains information such as `restaurant`, `name`, `items`, and `total`, the column `delivery_address` is often missing for UCSD students. The missingness mechanism of these columns is likely:\n",
    "    - Is the exam grade column `MD`, `MCAR`, `MAR`, `NI`?\n",
    "1. In a database of student records that records student profile data, such as `name`, `home_address`, `ethnicity`, etc., sometimes the Middle Name column is missing. This column is most likely:\n",
    "    - `MD`, `MCAR`, `MAR`, `NI`\n",
    "1. The UCSD Club Basketball team creates a signup sheet for potential new members. The sheet contains the columns: `full_name`, `year`, `email`, `favorite_sports`, `number_of_sports_played`, `sports_previously_played`. The team president notices that many students left the `sports_previously_played` blank. The missingness mechanism of this column is likely:\n",
    "    - `MD`, `MCAR`, `MAR`, `NI`\n",
    "1. Associated Students sends out a survey to all students about their 2019 Sun God Experience, with all questions being optional. They notice that many students left the \"Were you satisfied with Sun God 2019?\". This missingness is most likely:\n",
    "    - `MD`, `MCAR`, `MAR`, `NI`\n",
    "1. UC San Diego is implementing two-step login through DUO on October 16th. On October 1st, an administrator creates a table of randomized student codes for all students (not their PID) and the phone numbers associated with their DUO account (two columns total). The administrator notices that there is a lot of missingness in the phone numbers column. This column is most likely:\n",
    "    - `MD`, `MCAR`, `MAR`, `NI`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
