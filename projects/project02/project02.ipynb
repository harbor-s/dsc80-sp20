{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Project 02\n",
    "\n",
    "### Checkpoint Due Date: Thursday, January 30 11:59:59 PM (Q1-5)\n",
    "\n",
    "### Final Due Date: Thursday, February 6 11:59:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Instructions\n",
    "\n",
    "This Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems.  \n",
    "* Like the lab, your coding work will be developed in the accompanying `projectXX.py` file, that will be imported into the current notebook. This code will be autograded.\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the HW! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `projectXX.py` (much like we do in the notebook).\n",
    "- Always document your code!\n",
    "\n",
    "## Checkpoint Instructions\n",
    "\n",
    "* The checkpoint requires you to turn in **questions 1-5**; \n",
    "* The checkpoint will be graded for *approximate* correctness: easier than the final tests; harder than the doctests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:24.832772Z",
     "start_time": "2019-10-14T01:51:24.805738Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:25.681889Z",
     "start_time": "2019-10-14T01:51:24.834879Z"
    }
   },
   "outputs": [],
   "source": [
    "import project02 as proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.042046Z",
     "start_time": "2019-10-14T01:51:25.685618Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Investigation into Flight Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The flights dataset\n",
    "\n",
    "The department of transportation has all flight delays for listed years on their [website](https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data). There are data for the years 1987 - 2018. See the description of columns in `data/columns.txt`.\n",
    "\n",
    "This project will look at a single year (2015) to keep the analysis \"simple\", which is available at the URL below (*NOT* on the data.gov site).\n",
    "\n",
    "\n",
    "* To download the flights dataset to your computer, use [this link](https://dsc80-fa19-data.s3-us-west-2.amazonaws.com/project02/flight-delays.zip), unzip the file, and place `flights.csv` in your project directory.\n",
    "\n",
    "* To download the dataset on `datahub.ucsd.edu` (this works on your computer as well!):\n",
    "    - Open the terminal in datahub (\"new > Terminal\")\n",
    "    - Change the directory to where you want your data (e.g. `cd [ASSIGNMENT_PATH]/data`)\n",
    "    - Download the unzipped dataset using these commands:\n",
    "        1. `wget https://dsc80-fa19-data.s3-us-west-2.amazonaws.com/project02/flight-delays.zip`\n",
    "        2. `unzip flight-delays.zip`\n",
    "    - `flights.csv` should be in the directory.\n",
    "    \n",
    "**NOTE: The unzipped files must be in the `project02/data` directory in order for the doctests to work!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your datasets\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "The flights dataset for 2015 is not small (~600MB). While you could likely load the entire dataset into Pandas on your laptop, if you wanted to work with more than one year, this would quickly become difficult (the data is available for 1987-2018). Therefore, we will filter down the dataset into two smaller files without ever reading the larger dataset fully into memory. We are going to create two smaller datasets:\n",
    "\n",
    "1. All flights arriving or departing from San Diego International Airport in 2015.\n",
    "2. All flights flown by either JetBlue or Southwest Airline in 2015.\n",
    "\n",
    "---\n",
    "\n",
    "To do this, you are going to use the `chunksize=N` keyword in Pandas `read_csv` to read the flights dataset in blocks of `N` lines. When you use this keyword argument, `pd.read_csv(fp, chunksize=N)` becomes a *iterator* that iterates through dataframes of length N until you have reached the end of the dataset. A typical pattern looks like:\n",
    "```\n",
    "L = pd.read_csv(filepath, chunksize=1000)\n",
    "for df in L:\n",
    "    process(df)\n",
    "```\n",
    "Where each `df` is a dataframe of length 1000. \n",
    "\n",
    "The processing you are going to do is:\n",
    "1. Iterate through the dataset, chunk-by-chunk,\n",
    "2. Filtering out rows of each chunk\n",
    "3. Incrementally add to a filtered csv file (since the data is perhaps too big to keep in memory). Keep in mind, if you want to keep writing to the same file, the mode='a' keyword in the `.to_csv` method can be helpful when calling it in the loop (a stands for 'append')\n",
    "\n",
    "---\n",
    "\n",
    "Write two functions that create the datasets below, using the 'chunking' pattern described above. Your functions should use `chunksize` of 10000.\n",
    "1. `get_san` which takes in a filepath containing all flights and an filepath where filtered dataset #1 is written. The function should return `None`.\n",
    "1. `get_jb_sw` which takes in a filepath containing all flights and an filepath where filtered dataset #2 is written. The function should return `None`.\n",
    "\n",
    "*Remark 1*: **Gradescope autograding servers are quite small and can't load this dataset into memory** -- so your code that reads in the large `flights.csv` dataset *must* work with chunks of the dataset one at a time to pass!\n",
    "\n",
    "*Remark 2:* You can check your work using the datasets included in the zip file!\n",
    "\n",
    "Remember to close your file properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 31) Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\n",
      "       'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
      "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
      "       'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
      "       'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME',\n",
      "       'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED', 'CANCELLATION_REASON',\n",
      "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
      "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "infp = os.path.join('data', 'flights.test')\n",
    "outfp = os.path.join('data', 'santest.tmp')\n",
    "proj.get_san(infp,outfp)\n",
    "df = pd.read_csv(outfp)\n",
    "print(df.shape,df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AA', 'UA', 'WN', 'NK', 'B6', 'AS', 'DL', 'US', 'OO'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join('data','flights.test'))['AIRLINE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 31) Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\n",
      "       'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
      "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
      "       'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
      "       'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME',\n",
      "       'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED', 'CANCELLATION_REASON',\n",
      "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
      "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "infp = os.path.join('data', 'flights.test')\n",
    "out2fp = os.path.join('data', 'jbswtest.tmp')\n",
    "proj.get_sw_jb(infp,outfp)\n",
    "df = pd.read_csv(outfp)\n",
    "print(df.shape,df.columns)\n",
    "os.remove(out2fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(outfp)\n",
    "    os.remove(out2fp)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delays to/from San Diego\n",
    "\n",
    "The department of transportation has all flight delays for listed years on their [website](https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data). \n",
    "\n",
    "The zip file at the [URL](https://dsc80-fa19-data.s3-us-west-2.amazonaws.com/project02/flight-delays.zip) contains a file `to_from_san.csv` that consists of all flights either to or from SAN (San Diego) in 2015 -- i.e. the output of Question 1. This dataset should match the dataset that your code returned in question 1.\n",
    "\n",
    "Read in `to_from_san.csv` using `read_csv` and inspect the dataframe for an initial assessment about the data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.403770Z",
     "start_time": "2019-10-14T01:51:26.045071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "to_from_san_filepath = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(to_from_san_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data types of the columns\n",
    "\n",
    "**Question 2**:\n",
    "\n",
    "* First, classify the *kind* of data each column in `flights` contains. Create a function `data_kinds` of zero variables which outputs a (hard-coded) dictionary of data kinds, keyed by column name, with values `Q`, `O`, `N` (for 'Quantitative', 'Ordinal', or 'Nominal').\n",
    "\n",
    "* Second, decide the best data *type* for each column. Create a function `data_types` of zero variables which outputs a (hard-coded) dictionary of data types, keyed by column name, with values `str`, `int`, `float`, `bool`. \n",
    "\n",
    "*Remark 1*: A column which *should* be `int`s, but contains `NaN`, *must* be a float column. See Lecture 2 notes an explanation of `NaN` and data-types.\n",
    "\n",
    "*Remark 2*: As with real data, some data processing decisions may be ambiguous here. Make a best decision using the information available to you. It may be helpful to (re)read the relevant [section of the textbook](https://afraenkel.github.io/practical-data-science/03/kinds-of-data.html). \n",
    "* Certain answers *may* have more than one correct answer (in these cases, more than one choice gets full credit),\n",
    "* All answers will be graded for partial credit (some wrong answers are more wrong than other).\n",
    "There are many columns, so don't worry about the correctness of any given one; do make sure you are thinking about what's contained in a column critically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the typed flights data\n",
    "\n",
    "Read in the flights data using your dictionary of data-types in `read_csv`. This both speeds up parsing, as well as gives you the correct data-types upon reading (which columns would pandas *parse incorrectly* if you didn't use a `dtype` dictionary?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.410356Z",
     "start_time": "2019-10-14T01:51:24.819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "dtypes = proj.data_types()\n",
    "flights = pd.read_csv(to_from_san_filepath, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 (Basic Stats):**\n",
    "\n",
    "Define a function `basic_stats` that takes a dataframe `flights` and outputs a dataframe that contains statistics for flights arriving/departing for SAN. That is, the output should have two rows, indexed by `ARRIVING` and `DEPARTING`, and have the following columns:\n",
    "\n",
    "1. number of arriving/departing flights to/from SAN (`count`).\n",
    "2. mean flight (arrival) delay of arriving/departing flights to/from SAN (`mean_delay`).\n",
    "3. median flight (arrival) delay of arriving/departing flights to/from SAN (`median_delay`).\n",
    "4. the airline code of the airline with the longest flight (arrival) delay among all flights arriving/departing to/from SAN (`airline`).\n",
    "5. a list of the three months with the greatest number of arriving/departing flights to/from SAN, sorted from greatest to least (`top_months`).\n",
    "\n",
    "*Remark:* Null values should not be considered when computing statistics; however, think about whether e.g. the average flight delay is likely higher or lower that the \"true mean\" by making this choice.\n",
    "\n",
    "*Hint*: Use `groupbby` and the fact that `aggregate` can take in a dictionary as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding flight delays: Departures, Arrivals, and everything in-between\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "Often `DEPARTURE_DELAY` is thought to be the main cause of a flight delay -- i.e., when the flight is late pushing off from the gate. \n",
    "\n",
    "However, there are other ways that flights can be late: waiting on the tarmac, headwinds, turbulence, circling a busy airport, and waiting for a gate after landing. First, we will analyze all the ways in which a flight can be delayed.\n",
    "\n",
    "* First, create a function `depart_arrive_stats` that takes in a dataframe like `flights` and calculates the following quantities in a series, indexed by `late1`, `late2`, `late3`:\n",
    "    - The proportion of flights from/to SAN that leave late, but arrive early or on-time (`late1`).\n",
    "    - The proportion of flights from/to SAN that leaves early, or on-time, but arrives late (`late2`).\n",
    "    - The proportion of flights from/to SAN that both left late and arrived late (`late3`).\n",
    "    \n",
    "* Second, create a function `depart_arrive_stats_by_month` that takes in a dataframe like `flights` and calculates the quantities above broken down by *month*. That is, the output is a dataframe, indexed by `MONTH`, with columns given by `late1`, `late2`, `late3`.\n",
    "\n",
    "*Remark 1:* Does this question reveal any data quality issues? Can you pinpoint when these issues occur?\n",
    "\n",
    "*Remark 2:* A flight is considered late if it departed/arrived any time later than its planned departure/arrival time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\n",
       "       'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
       "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
       "       'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
       "       'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME',\n",
       "       'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED', 'CANCELLATION_REASON',\n",
       "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
       "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight delays and day of the week\n",
    "\n",
    "**Question 5**\n",
    "\n",
    "Next, we'd like to understand the flight traffic to/from SAN by day of the week. Day of the week is specified by integers 1 through 7; verify for yourself which integer corresponds to which day (hint: you have the *date* for each flight as well!).\n",
    "\n",
    "Next create two functions to understand both the amount of traffic and the average flight delay of flights for each airline by day-of-the week. We both want to understand *presence* each airline has as well as their *performance*.\n",
    "\n",
    "1. Create a function `cnts_by_airline_dow` that takes in a dataframe like `flights` and outputs a dataframe that answers the following question: Given any `AIRLINE` and `DAY_OF_WEEK`, how many flights were there (in 2015)?\n",
    "\n",
    "\n",
    "2. Create a function `mean_by_airline_dow` that takes in a dataframe like `flights` and outputs a dataframe that answers the following question: Given any `AIRLINE` and `DAY_OF_WEEK`, what is the average `ARRIVAL_DELAY` (in 2015)?\n",
    "\n",
    "Both dataframes should have a column for each distinct value of `AIRLINE` and a row for each `DAY_OF_WEEK`.\n",
    "\n",
    "*Hint:* Both `groupby` and `pivot` should be useful here!\n",
    "\n",
    "Your output should have the *form* of the table below (not the entries themselves!)\n",
    "\n",
    "<img src=\"pivot.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.245981</td>\n",
       "      <td>-2.652286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-3.096904</td>\n",
       "      <td>3.233945</td>\n",
       "      <td>5.842105</td>\n",
       "      <td>9.222656</td>\n",
       "      <td>7.405257</td>\n",
       "      <td>3.081280</td>\n",
       "      <td>1.764344</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>6.355997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.791037</td>\n",
       "      <td>-4.535474</td>\n",
       "      <td>4.507123</td>\n",
       "      <td>-2.988408</td>\n",
       "      <td>4.975728</td>\n",
       "      <td>7.385417</td>\n",
       "      <td>10.669903</td>\n",
       "      <td>5.109574</td>\n",
       "      <td>5.617431</td>\n",
       "      <td>1.354626</td>\n",
       "      <td>4.645522</td>\n",
       "      <td>5.394194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.811808</td>\n",
       "      <td>-4.030899</td>\n",
       "      <td>2.735043</td>\n",
       "      <td>-2.437098</td>\n",
       "      <td>5.634361</td>\n",
       "      <td>16.833333</td>\n",
       "      <td>6.304264</td>\n",
       "      <td>5.566741</td>\n",
       "      <td>3.686344</td>\n",
       "      <td>-2.145299</td>\n",
       "      <td>0.631970</td>\n",
       "      <td>3.556762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.076552</td>\n",
       "      <td>-2.180995</td>\n",
       "      <td>3.152406</td>\n",
       "      <td>-2.339721</td>\n",
       "      <td>4.531818</td>\n",
       "      <td>7.552083</td>\n",
       "      <td>7.931298</td>\n",
       "      <td>7.971901</td>\n",
       "      <td>4.957124</td>\n",
       "      <td>1.198397</td>\n",
       "      <td>8.277040</td>\n",
       "      <td>6.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.235679</td>\n",
       "      <td>-1.040887</td>\n",
       "      <td>3.329759</td>\n",
       "      <td>-5.699528</td>\n",
       "      <td>4.830918</td>\n",
       "      <td>8.021505</td>\n",
       "      <td>7.242718</td>\n",
       "      <td>5.920156</td>\n",
       "      <td>1.756997</td>\n",
       "      <td>3.017928</td>\n",
       "      <td>9.325536</td>\n",
       "      <td>7.961504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.427912</td>\n",
       "      <td>-3.283673</td>\n",
       "      <td>-1.854478</td>\n",
       "      <td>-3.608726</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>7.159574</td>\n",
       "      <td>6.943026</td>\n",
       "      <td>3.746961</td>\n",
       "      <td>-1.338924</td>\n",
       "      <td>-2.227926</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>1.684625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.611924</td>\n",
       "      <td>-2.318213</td>\n",
       "      <td>2.422043</td>\n",
       "      <td>-4.857392</td>\n",
       "      <td>6.112150</td>\n",
       "      <td>5.229167</td>\n",
       "      <td>8.754753</td>\n",
       "      <td>8.570806</td>\n",
       "      <td>-0.190121</td>\n",
       "      <td>2.257545</td>\n",
       "      <td>12.594533</td>\n",
       "      <td>6.867543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AIRLINE            AA        AS        B6        DL        F9         HA  \\\n",
       "DAY_OF_WEEK                                                                \n",
       "1            2.245981 -2.652286  0.928571 -3.096904  3.233945   5.842105   \n",
       "2            0.791037 -4.535474  4.507123 -2.988408  4.975728   7.385417   \n",
       "3            1.811808 -4.030899  2.735043 -2.437098  5.634361  16.833333   \n",
       "4            4.076552 -2.180995  3.152406 -2.339721  4.531818   7.552083   \n",
       "5            1.235679 -1.040887  3.329759 -5.699528  4.830918   8.021505   \n",
       "6           -0.427912 -3.283673 -1.854478 -3.608726  0.119171   7.159574   \n",
       "7            1.611924 -2.318213  2.422043 -4.857392  6.112150   5.229167   \n",
       "\n",
       "AIRLINE             NK        OO        UA        US         VX        WN  \n",
       "DAY_OF_WEEK                                                                \n",
       "1             9.222656  7.405257  3.081280  1.764344  12.804878  6.355997  \n",
       "2            10.669903  5.109574  5.617431  1.354626   4.645522  5.394194  \n",
       "3             6.304264  5.566741  3.686344 -2.145299   0.631970  3.556762  \n",
       "4             7.931298  7.971901  4.957124  1.198397   8.277040  6.582300  \n",
       "5             7.242718  5.920156  1.756997  3.017928   9.325536  7.961504  \n",
       "6             6.943026  3.746961 -1.338924 -2.227926   0.101370  1.684625  \n",
       "7             8.754753  8.570806 -0.190121  2.257545  12.594533  6.867543  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby(['DAY_OF_WEEK', 'AIRLINE'], as_index=False)['YEAR'].count().pivot(index='DAY_OF_WEEK', columns='AIRLINE', values='YEAR')\n",
    "proj.mean_by_airline_dow(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_delay</th>\n",
       "      <th>median_delay</th>\n",
       "      <th>airline</th>\n",
       "      <th>top_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ARRIVING</td>\n",
       "      <td>70207</td>\n",
       "      <td>3.676826</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>[2, 11, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DEPARTING</td>\n",
       "      <td>70207</td>\n",
       "      <td>3.328988</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>[2, 11, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  mean_delay  median_delay airline  top_months\n",
       "ARRIVING   70207    3.676826          -4.0      AA  [2, 11, 1]\n",
       "DEPARTING  70207    3.328988          -5.0      AA  [2, 11, 1]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.basic_stats(flights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding null values in the flights data\n",
    "\n",
    "**Question 6 (Missing by Design)**\n",
    "\n",
    "Now we would like to understand how data is missing in the flights data. First, compute the proportion of each column of `flights` which are non-null. Do not turn this in, but it will be useful information in doing the next few problems.\n",
    "\n",
    "Recall that a column is *missing by design* if you can determine when the entry of a column is missing based solely on other data in the same row. That is\n",
    "* there is *no randomness* in determining when an entry is missing.\n",
    "* you can describe when the column is missing a value with a logical (not random) condition.\n",
    "* you can express which rows will have missing values in terms of logical statements about the *other* columns in the same row.\n",
    "\n",
    "For this question, verify the following columns are *missing by design*:\n",
    "* The column `ARRIVAL_DELAY` is *missing by design*. Create a function `predict_null_arrival_delay` that doesn't depend on the values of `ARRIVAL_DELAY`, that:\n",
    "    - Takes in a row of the flights data (that is, a Series)\n",
    "    - Returns `True` if and only if the `ARRIVAL_DELAY` is null; otherwise it returns `False`.\n",
    "    - Since the function doesn't depend on `ARRIVAL_DELAY`, it should work on a row even if the `ARRIVAL_DELAY` index is dropped.\n",
    "    - You can check your function by using `flights.drop('ARRIVAL_DELAY', axis=1).apply(predict_null, axis=1)` and compare it to the `ARRIVAL_DELAY` column!\n",
    "\n",
    "\n",
    "* The column `AIRLINE_DELAY` is *missing by design*. As above, create a function `predict_null_airline_delay` that doesn't depend on the values of `AIRLINE_DELAY`, that:\n",
    "    - Takes in a row of the flights data (that is, a Series)\n",
    "    - Returns `True` if and only if the `AIRLINE_DELAY` is null; otherwise it returns `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TAIL_NUMBER            0.998512\n",
       "DEPARTURE_TIME         0.990001\n",
       "DEPARTURE_DELAY        0.990001\n",
       "TAXI_OUT               0.989638\n",
       "WHEELS_OFF             0.989638\n",
       "ELAPSED_TIME           0.986825\n",
       "AIR_TIME               0.986825\n",
       "WHEELS_ON              0.988961\n",
       "TAXI_IN                0.988961\n",
       "ARRIVAL_TIME           0.988961\n",
       "ARRIVAL_DELAY          0.986825\n",
       "CANCELLATION_REASON    0.010426\n",
       "AIR_SYSTEM_DELAY       0.179875\n",
       "SECURITY_DELAY         0.179875\n",
       "AIRLINE_DELAY          0.179875\n",
       "LATE_AIRCRAFT_DELAY    0.179875\n",
       "WEATHER_DELAY          0.179875\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = flights.count() / flights.shape[0]\n",
    "s.loc[s<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2337</td>\n",
       "      <td>N553AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90307</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>OO</td>\n",
       "      <td>4845</td>\n",
       "      <td>N825SK</td>\n",
       "      <td>SAN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90275</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>OO</td>\n",
       "      <td>5207</td>\n",
       "      <td>N120SY</td>\n",
       "      <td>SAN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1850</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90268</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>OO</td>\n",
       "      <td>4845</td>\n",
       "      <td>N825SK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SAN</td>\n",
       "      <td>1835</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90238</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>OO</td>\n",
       "      <td>6531</td>\n",
       "      <td>N120SY</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SAN</td>\n",
       "      <td>1720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42340</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>WN</td>\n",
       "      <td>3221</td>\n",
       "      <td>N626SW</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SAN</td>\n",
       "      <td>815</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41939</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>AA</td>\n",
       "      <td>369</td>\n",
       "      <td>N854AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41636</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>1445</td>\n",
       "      <td>N855AA</td>\n",
       "      <td>SAN</td>\n",
       "      <td>DFW</td>\n",
       "      <td>1420</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40665</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>459</td>\n",
       "      <td>N3755D</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SAN</td>\n",
       "      <td>825</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140408</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1042</td>\n",
       "      <td>N870AA</td>\n",
       "      <td>SAN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2210</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1464 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "60      2015      1    1            4      AA           2337      N553AA   \n",
       "90307   2015      8    1            6      OO           4845      N825SK   \n",
       "90275   2015      8    1            6      OO           5207      N120SY   \n",
       "90268   2015      8    1            6      OO           4845      N825SK   \n",
       "90238   2015      8    1            6      OO           6531      N120SY   \n",
       "...      ...    ...  ...          ...     ...            ...         ...   \n",
       "42340   2015      4   15            3      WN           3221      N626SW   \n",
       "41939   2015      4   14            2      AA            369      N854AA   \n",
       "41636   2015      4   13            1      AA           1445      N855AA   \n",
       "40665   2015      4   11            6      DL            459      N3755D   \n",
       "140408  2015     12   31            4      AA           1042      N870AA   \n",
       "\n",
       "       ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  \\\n",
       "60                DFW                 SAN                  900  ...   \n",
       "90307             SAN                 LAX                 2012  ...   \n",
       "90275             SAN                 LAX                 1850  ...   \n",
       "90268             LAX                 SAN                 1835  ...   \n",
       "90238             LAX                 SAN                 1720  ...   \n",
       "...               ...                 ...                  ...  ...   \n",
       "42340             SFO                 SAN                  815  ...   \n",
       "41939             DFW                 SAN                  900  ...   \n",
       "41636             SAN                 DFW                 1420  ...   \n",
       "40665             JFK                 SAN                  825  ...   \n",
       "140408            SAN                 MIA                 2210  ...   \n",
       "\n",
       "        ARRIVAL_TIME  ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  \\\n",
       "60               NaN            NaN         0          1                    B   \n",
       "90307            NaN            NaN         0          1                    A   \n",
       "90275            NaN            NaN         0          1                    A   \n",
       "90268            NaN            NaN         0          1                    A   \n",
       "90238            NaN            NaN         0          1                    A   \n",
       "...              ...            ...       ...        ...                  ...   \n",
       "42340            NaN            NaN         0          1                    A   \n",
       "41939            NaN            NaN         0          1                    B   \n",
       "41636            NaN            NaN         0          1                    B   \n",
       "40665            NaN            NaN         0          1                    A   \n",
       "140408           NaN            NaN         0          1                    A   \n",
       "\n",
       "        AIR_SYSTEM_DELAY  SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  \\\n",
       "60                   NaN             NaN            NaN                  NaN   \n",
       "90307                NaN             NaN            NaN                  NaN   \n",
       "90275                NaN             NaN            NaN                  NaN   \n",
       "90268                NaN             NaN            NaN                  NaN   \n",
       "90238                NaN             NaN            NaN                  NaN   \n",
       "...                  ...             ...            ...                  ...   \n",
       "42340                NaN             NaN            NaN                  NaN   \n",
       "41939                NaN             NaN            NaN                  NaN   \n",
       "41636                NaN             NaN            NaN                  NaN   \n",
       "40665                NaN             NaN            NaN                  NaN   \n",
       "140408               NaN             NaN            NaN                  NaN   \n",
       "\n",
       "        WEATHER_DELAY  \n",
       "60                NaN  \n",
       "90307             NaN  \n",
       "90275             NaN  \n",
       "90268             NaN  \n",
       "90238             NaN  \n",
       "...               ...  \n",
       "42340             NaN  \n",
       "41939             NaN  \n",
       "41636             NaN  \n",
       "40665             NaN  \n",
       "140408            NaN  \n",
       "\n",
       "[1464 rows x 31 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.loc[flights['ARRIVAL_DELAY'].isna() & (flights['DIVERTED'] == 0)].sort_values('CANCELLED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flights.drop('AIRLINE_DELAY', axis=1).apply(proj.predict_null_airline_delay, axis=1) != flights['AIRLINE_DELAY'].isna()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -4.0\n",
       "1         -1.0\n",
       "2          0.0\n",
       "3         -3.0\n",
       "4         -2.0\n",
       "          ... \n",
       "140409    -7.0\n",
       "140410     5.0\n",
       "140411   -14.0\n",
       "140412    -2.0\n",
       "140413     4.0\n",
       "Name: DEPARTURE_DELAY, Length: 140414, dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights['DEPARTURE_DELAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7 (Missingness Types)**\n",
    "\n",
    "Now we'd like to determine missingness of the column `DEPARTURE_DELAY`. In particular, we'd like to perform a permutation test to determine the missingness of `DEPARTURE_DELAY` dependent on the column `AIRLINE`.\n",
    "\n",
    "* Create a function `perm4missing`:\n",
    "    - that takes in `flights`, a column `col`, and a number `N` and \n",
    "    - returns the p-value of the test (using `N` simulations) that determines if `DEPARTURE_DELAY` is MAR dependent on `col`. That is `perm4missing(flights, 'AIRLINE', N)` should return the p-value for the test above.\n",
    "    - *Remark*: to help your work, create helper functions whose output you can plot, to assess the correctness of your p-value!\n",
    "    \n",
    "* Use your function above to determine the columns `col` for which \"`DEPARTURE_DELAY` is MAR dependent on `col`\" using a significance level of 0.01. Only consider the categorical columns `YEAR`,`DAY_OF_WEEK`, `AIRLINE`,`DIVERTED`, `CANCELLATION_REASON`. Return your answer in a (hard-coded) list returned by a function called `dependent_cols`.\n",
    "\n",
    "* Create a function `missing_types` of zero variables, which:\n",
    "    - Returns a Series, indexed by the following columns of `flights`: `CANCELLED`, `CANCELLATION_REASON`, `TAIL_NUMBER`, `ARRIVAL_TIME`.\n",
    "    - The values should contain the most-likely missingness type of each column. \n",
    "    - The values of this Series should be `MD, MCAR, MAR, MNAR, NaN` (use `NaN` if there are no missing values). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.perm4missing(flights,'YEAR', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-287-57f3063418c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperm4missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DAY_OF_WEEK'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GitHub/dsc80-sp20/projects/project02/project02.py\u001b[0m in \u001b[0;36mperm4missing\u001b[0;34m(flights, col, N)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mshuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'delays'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvd_tf_delays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mobs_stat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/dsc80-sp20/projects/project02/project02.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(df, col)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mshuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3647\u001b[0m         \u001b[0mBerkeley\u001b[0m    \u001b[0;36m25.0\u001b[0m    \u001b[0;36m77.0\u001b[0m  \u001b[0;36m298.15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3648\u001b[0m         \"\"\"\n\u001b[0;32m-> 3649\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m         \u001b[0;31m# >= 3.6 preserve order of kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5994\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5995\u001b[0m         \"\"\"\n\u001b[0;32m-> 5996\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5997\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         bm = self.__class__(\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         )\n\u001b[1;32m    446\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gaps in blk ref_locs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proj.perm4missing(flights,'DAY_OF_WEEK',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.perm4missing(flights,'AIRLINE',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.perm4missing(flights,'DIVERTED',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.perm4missing(flights,'CANCELLATION_REASON',10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpson's Paradox: JetBlue vs Southwest\n",
    "\n",
    "The remainder of the questions investigates the presence of Simpson's paradox in the flights dataset. Read through the final slides of lecture 05, as well as [the book](https://afraenkel.github.io/practical-data-science/05/understanding-aggregations.html#simpsons-paradox) for a summary of Simpson's Paradox and related links.\n",
    "\n",
    "The csv file `southwest_vs_jetblue.csv` contains all Southwest and JetBlue flights in 2015.\n",
    "\n",
    "In this dataset, we are going to verify the following occurrences of Simpson's Paradox: For a given set of airports,\n",
    "* The average departure delay of Southwest is greater than (or less than) the average departure delay of JetBlue.\n",
    "* Airport by airport, the average departure delay of Southwest is *less* than (or greater than) the average departure delay of JetBlue.\n",
    "\n",
    "That is, the inequalities of the average flight delays between the two airlines are reversed when viewed at the level of each airport. In fact this reversal holds for *every* airport being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.412337Z",
     "start_time": "2019-10-14T01:51:24.838Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "jb_sw_filepath = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "dtype = proj.data_types()\n",
    "\n",
    "# The `usecols` keyword:\n",
    "# choose *only* the columns you need to reduce your memory footprint!\n",
    "usecols = ['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT','DEPARTURE_DELAY','CANCELLED']\n",
    "\n",
    "jb_sw = pd.read_csv(jb_sw_filepath, dtype=dtype, usecols=usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1222707</td>\n",
       "      <td>WN</td>\n",
       "      <td>10140</td>\n",
       "      <td>14679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1269595</td>\n",
       "      <td>WN</td>\n",
       "      <td>10140</td>\n",
       "      <td>14679</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1198135</td>\n",
       "      <td>WN</td>\n",
       "      <td>10140</td>\n",
       "      <td>11259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1193368</td>\n",
       "      <td>WN</td>\n",
       "      <td>10140</td>\n",
       "      <td>11292</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182058</td>\n",
       "      <td>WN</td>\n",
       "      <td>10140</td>\n",
       "      <td>14107</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1083867</td>\n",
       "      <td>WN</td>\n",
       "      <td>TUS</td>\n",
       "      <td>SAN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139853</td>\n",
       "      <td>WN</td>\n",
       "      <td>TUS</td>\n",
       "      <td>SAN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231861</td>\n",
       "      <td>WN</td>\n",
       "      <td>TUS</td>\n",
       "      <td>MDW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59308</td>\n",
       "      <td>WN</td>\n",
       "      <td>TUS</td>\n",
       "      <td>LAS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602782</td>\n",
       "      <td>WN</td>\n",
       "      <td>TUS</td>\n",
       "      <td>SAN</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528903 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AIRLINE ORIGIN_AIRPORT DESTINATION_AIRPORT  DEPARTURE_DELAY  CANCELLED\n",
       "1222707      WN          10140               14679              1.0          0\n",
       "1269595      WN          10140               14679             -1.0          0\n",
       "1198135      WN          10140               11259              5.0          0\n",
       "1193368      WN          10140               11292             46.0          0\n",
       "1182058      WN          10140               14107             -3.0          0\n",
       "...         ...            ...                 ...              ...        ...\n",
       "1083867      WN            TUS                 SAN              9.0          0\n",
       "139853       WN            TUS                 SAN             22.0          0\n",
       "231861       WN            TUS                 MDW              4.0          0\n",
       "59308        WN            TUS                 LAS              2.0          0\n",
       "602782       WN            TUS                 SAN             -3.0          0\n",
       "\n",
       "[1528903 rows x 5 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb_sw.sort_values('ORIGIN_AIRPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**\n",
    "\n",
    "Filter the dataset `jb_sw` to flights *originating* from the following 10 airports: ABQ, BDL, BUR, DCA, MSY, PBI, PHX, RNO, SJC, SLC.\n",
    "\n",
    "Illustrate Simpson's paradox with this table:\n",
    "* Calculate the proportion of each airline's flights that are delayed (at each of the 10 airports):\n",
    "    - Create a function `prop_delayed_by_airline` that takes in a dataframe like `jb_sw` and returns a DataFrame indexed by airline that contains the proportion of each airline's flights that are delayed.\n",
    "* Calculate these proportions across all airports in the dataset (at each of the 10 airports):\n",
    "    - Create a function `prop_delayed_by_airline_airport` that takes in a dataframe like `jb_sw` and returns a DataFrame, with columns given by airports, indexed by airline, that contains the proportion of each airline's flights that are delayed at each airport.\n",
    "\n",
    "*Remark 1:* For the purpose of this question, a canceled flight is **not** considered delayed.\n",
    "\n",
    "*Remark 2:* Make sure that the functions only work with the columns that are absolutely necessary for the question to avoid out of memory errors!\n",
    "\n",
    "Verify that Simpson's paradox is present in this output! \n",
    "\n",
    "Can you explain *why* Simpson's paradox is occurring? (Hint: where are these airports located? Which have the most flights?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>ABQ</th>\n",
       "      <th>BDL</th>\n",
       "      <th>BUR</th>\n",
       "      <th>DCA</th>\n",
       "      <th>MSY</th>\n",
       "      <th>PBI</th>\n",
       "      <th>PHX</th>\n",
       "      <th>RNO</th>\n",
       "      <th>SJC</th>\n",
       "      <th>SLC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>B6</td>\n",
       "      <td>0.489051</td>\n",
       "      <td>0.371207</td>\n",
       "      <td>0.449102</td>\n",
       "      <td>0.284724</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.476827</td>\n",
       "      <td>0.574661</td>\n",
       "      <td>0.544379</td>\n",
       "      <td>0.516899</td>\n",
       "      <td>0.485859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WN</td>\n",
       "      <td>0.457208</td>\n",
       "      <td>0.367560</td>\n",
       "      <td>0.342187</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.377690</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>0.549093</td>\n",
       "      <td>0.377817</td>\n",
       "      <td>0.464479</td>\n",
       "      <td>0.441616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ORIGIN_AIRPORT       ABQ       BDL       BUR       DCA       MSY       PBI  \\\n",
       "AIRLINE                                                                      \n",
       "B6              0.489051  0.371207  0.449102  0.284724  0.391111  0.476827   \n",
       "WN              0.457208  0.367560  0.342187  0.283721  0.377690  0.428290   \n",
       "\n",
       "ORIGIN_AIRPORT       PHX       RNO       SJC       SLC  \n",
       "AIRLINE                                                 \n",
       "B6              0.574661  0.544379  0.516899  0.485859  \n",
       "WN              0.549093  0.377817  0.464479  0.441616  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb_sw = jb_sw.loc[jb_sw['ORIGIN_AIRPORT'].isin(['ABQ','BDL','BUR','DCA','MSY','PBI','PHX','RNO','SJC','SLC'])]\n",
    "df = jb_sw.copy()\n",
    "df['delayed']= jb_sw['DEPARTURE_DELAY'].apply(lambda x: 1 if x>0 else 0)\n",
    "df['delayed'] = df['delayed']-df['CANCELLED']\n",
    "df['delayed'] = df['delayed'].apply(lambda x: 0 if x==-1 else x)\n",
    "#df['delay']\n",
    "df.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT',aggfunc='mean', values='delayed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>ABQ</th>\n",
       "      <th>BDL</th>\n",
       "      <th>BUR</th>\n",
       "      <th>DCA</th>\n",
       "      <th>MSY</th>\n",
       "      <th>PBI</th>\n",
       "      <th>PHX</th>\n",
       "      <th>RNO</th>\n",
       "      <th>SJC</th>\n",
       "      <th>SLC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>B6</td>\n",
       "      <td>0.489051</td>\n",
       "      <td>0.371207</td>\n",
       "      <td>0.449102</td>\n",
       "      <td>0.284724</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.476827</td>\n",
       "      <td>0.574661</td>\n",
       "      <td>0.544379</td>\n",
       "      <td>0.516899</td>\n",
       "      <td>0.485859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WN</td>\n",
       "      <td>0.457208</td>\n",
       "      <td>0.367560</td>\n",
       "      <td>0.342187</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.377690</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>0.549093</td>\n",
       "      <td>0.377817</td>\n",
       "      <td>0.464479</td>\n",
       "      <td>0.441616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ORIGIN_AIRPORT       ABQ       BDL       BUR       DCA       MSY       PBI  \\\n",
       "AIRLINE                                                                      \n",
       "B6              0.489051  0.371207  0.449102  0.284724  0.391111  0.476827   \n",
       "WN              0.457208  0.367560  0.342187  0.283721  0.377690  0.428290   \n",
       "\n",
       "ORIGIN_AIRPORT       PHX       RNO       SJC       SLC  \n",
       "AIRLINE                                                 \n",
       "B6              0.574661  0.544379  0.516899  0.485859  \n",
       "WN              0.549093  0.377817  0.464479  0.441616  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.prop_delayed_by_airline_airport(jb_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delayed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>B6</td>\n",
       "      <td>0.386425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WN</td>\n",
       "      <td>0.447068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          delayed\n",
       "AIRLINE          \n",
       "B6       0.386425\n",
       "WN       0.447068"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.prop_delayed_by_airline(jb_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>delayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>WN</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>WN</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>B6</td>\n",
       "      <td>PBI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>B6</td>\n",
       "      <td>MSY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>B6</td>\n",
       "      <td>DCA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1528882</td>\n",
       "      <td>B6</td>\n",
       "      <td>SJC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1528892</td>\n",
       "      <td>B6</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1528894</td>\n",
       "      <td>B6</td>\n",
       "      <td>RNO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1528895</td>\n",
       "      <td>B6</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1528897</td>\n",
       "      <td>B6</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178767 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AIRLINE ORIGIN_AIRPORT  delayed\n",
       "25           WN            ABQ        1\n",
       "26           WN            PHX        1\n",
       "31           B6            PBI        0\n",
       "41           B6            MSY        0\n",
       "46           B6            DCA        0\n",
       "...         ...            ...      ...\n",
       "1528882      B6            SJC        1\n",
       "1528892      B6            PHX        1\n",
       "1528894      B6            RNO        0\n",
       "1528895      B6            SLC        1\n",
       "1528897      B6            ABQ        1\n",
       "\n",
       "[178767 rows x 3 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = jb_sw.copy()\n",
    "df['delayed']= jb_sw['DEPARTURE_DELAY'].apply(lambda x: 1 if x>0 else 0)\n",
    "df = df.loc[:,['AIRLINE','ORIGIN_AIRPORT','delayed']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**\n",
    "\n",
    "Your work above illustrates Simpson's paradox on the specific dataset of flights originating from 10 specific airports. However, this still requires you to look at two dataframe to see if the paradox is present. Now, you will create a function that verifies Simpson's paradox in general. You will do this by writing code to compare the two dataframes, instead of inspecting them manually.\n",
    "\n",
    "Create a function `verify_simpson` that returns a boolean output regarding if the paradox is present.\n",
    "```\n",
    "verify_simpson(df, group1, group2, occur)\n",
    "```\n",
    "- df is a dataframe (e.g. jb_sw),\n",
    "- group1 is the first group being aggregated against (e.g. `AIRLINE`),\n",
    "- group2 is the second group being aggregated against (e.g. `ORIGIN_AIRPORT`),\n",
    "- occur is a column with values {0, 1}, denoting if an event occurred for that individual.\n",
    "  (e.g. \"1 if flight was delayed\" and \"0 if flight was not delayed\")\n",
    "\n",
    "`verify_simpson` should return `True` only if there is a reversal for *every* value of `group2` (e.g. for every airport).\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider the following dataframe `df` with columns `treatment`, `stone_size`, and `success`:\n",
    "\n",
    "|treatment|stone_size|success|\n",
    "|---|---|---|\n",
    "|A|small|1|\n",
    "|B|small|1|\n",
    "|...|...|...|\n",
    "|A|large|0|\n",
    "|B|small|0|\n",
    "|B|small|1|\n",
    "\n",
    "`df` corresponds to the following diagram:\n",
    "<img src=\"https://miro.medium.com/max/996/1*IfVjfdGD7RPwLDC6WzT9Uw.png\" style=\"width: 300px\"/>\n",
    "\n",
    "Here, `verify_simpson(df, 'treatment', 'stone_size', 'success')` should return `True`.\n",
    "\n",
    "Verify that you function works on the previous question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AIRLINE   delayed\n",
      "0      B6  0.386634\n",
      "1      WN  0.447210 1 0\n",
      "ORIGIN_AIRPORT       ABQ       BDL       BUR       DCA       MSY       PBI  \\\n",
      "AIRLINE                                                                      \n",
      "B6              0.489051  0.371207  0.449102  0.285039  0.391111  0.476827   \n",
      "WN              0.457300  0.367560  0.342187  0.284563  0.377690  0.428684   \n",
      "\n",
      "ORIGIN_AIRPORT       PHX       RNO       SJC       SLC  \n",
      "AIRLINE                                                 \n",
      "B6              0.576169  0.544379  0.518887  0.485859  \n",
      "WN              0.549186  0.377978  0.464572  0.441616  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.verify_simpson(df,'AIRLINE','ORIGIN_AIRPORT','delayed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus problem (worth zero points)\n",
    "\n",
    "This question is for fun and explores a very data-science type problem: can we automate finding examples of Simpson's Paradox? This is an active area of research (see for example: https://arxiv.org/pdf/1801.04385.pdf), but is a very accessible problem. While totally optional, this question can lead to pretty interesting self-driven projects!\n",
    "\n",
    "**Question 10 (Searching for Simpson's Paradox):**\n",
    "\n",
    "As you observed from the reading in the lecture notes, Simpson's Paradox often occurs due to some confounding factor among the columns of a dataset. In the case of gender balance in student admissions to academic departments at UC Berkeley, the confounding factor was the admission rate (i.e. how hard it is to gain admission to a department).\n",
    "\n",
    "What might be a confounding factor be for flight delays among airports in question 8? Now you are going to write code to discover instances of Simpson's Paradox; that is, you will programmatically find interesting relationships present in the data.\n",
    "\n",
    "Given the dataset `jb_sw`, we'd like to find new groups of airports, as in question 8, for which the statistics of flight delays between JetBlue and Southwest satisfy Simpson's Paradox.\n",
    "\n",
    "Create a function `search_simpsons` that takes in the `jb_sw` dataset and a number `N`, and returns a list of `N` airports for which the proportion of flight delays between JetBlue and Southwest satisfies Simpson's Paradox.\n",
    "- Only consider airports that have '3 letter codes',\n",
    "- Only consider airports that have at least one JetBlue *and* Southwest flight.\n",
    "\n",
    "*Remark 1:* Iterate through groups of airports of size `N` using `itertools.combinations` until you find a group that works. Make sure your function finishes, even if it doesn't find something.\n",
    "\n",
    "*Remark 2:* You should be using your work from Question 9!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, you finished the project!\n",
    "\n",
    "### Before you submit:\n",
    "* Be sure you run the doctests on all your code in project02.py\n",
    "\n",
    "### To submit:\n",
    "* **Upload the .py file to gradescope**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
